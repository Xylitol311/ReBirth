# 박종원 일자별 진행 내용

## 2025.03.04 화
### 아이디어 기획회의
- 마이크로 기부시스템 아이디어 제안
  - 의미: 소액 자동 기부 시스템을 통한 사회적 가치 창출 시도
  - 메커니즘: 14,900원 결제 시 100원 자동 추가 결제하여 기부

## 2025.03.05 수
### 마이크로 기부시스템 검토 및 기술적 논의
- QR 결제 대신 NFC 결제 방식 검토 (API 활용 가능성 확인)
- 결제 방식 제한사항 파악: MST 불가, NFC 카드 결제만 가능
- 네이티브 앱 개발 필요성 - 안드로이드 필수
- 결제 구조 설계: 가맹점 요금(14,900원), PG사 연동 필요(계약 소요 약 2주)
- 'A602' PAY 시스템 구축 제안
- 이중 결제 구조 설계: 정규 결제 + 카드사 정기결제 기능 활용 (100원)
- 자체 결제 시스템 구축으로 자금관리 및 토큰화 방안 검토
- 법적 요건 확인: 사업자 등록 필요, 기부금품 모집업 등록 조건 (불특정 다수 1,000만원 이상)


## 2025.03.06 목
### 모의투자 서비스 아이디어 제안
- 한국투자증권 API를 활용한 모의투자 서비스 컨셉 개발
- 사용자 타겟 및 핵심 가치 제안 정의
- 모의투자 교육적 요소와 게이미피케이션 접목 방안 논의
- API 기능 및 제한사항 초기 검토
- **필요 백엔드 기술 검토**:
  - API 통합: 한국투자증권 API 연동 메커니즘
  - 데이터베이스: 시계열 DB(주가 데이터), 관계형 DB(사용자, 거래)
  - 실시간 처리: 메시지 큐, 이벤트 스트리밍
  - 보안: 사용자 인증, API 키 관리, 데이터 암호화
  - 서버 아키텍처: 마이크로서비스 vs 모놀리틱 검토
- **개인 학습**: 금융 API 통합 보안 요구사항 연구
  - 금융 데이터 처리 관련 법규 검토
  - OAuth 인증 및 API 키 관리 방안 학습

- **개인 학습**: RabbitMQ vs Kafka 비교 
  - 메시지 브로커 아키텍처 차이점 분석
  - 각 시스템의 장단점 및 적합한 사용 사례 정리

### RabbitMQ vs Kafka: 핵심 비교

#### 사용 이유
금융 모의투자 서비스에서 메시지 브로커가 필요한 이유:
- **실시간 데이터 처리**: 주식 시세, 거래 주문을 지연 없이 처리
- **시스템 분리**: 주문 접수, 처리, 정산 등 컴포넌트 간 느슨한 결합
- **부하 관리**: 트래픽 피크 시 버퍼 역할로 시스템 안정성 확보

#### 핵심 차이점

| 특성 | RabbitMQ | Kafka |
|------|----------|-------|
| **아키텍처** | 메시지 브로커 (큐 중심) | 분산 스트리밍 플랫폼 (로그 중심) |
| **처리 방식** | Push 방식 | Pull 방식 |
| **확장성** | 중소규모 (초당 수만 메시지) | 대규모 (초당 수백만 메시지) |
| **메시지 보존** | 소비 후 삭제 | 설정 기간 동안 유지 (리플레이 가능) |
| **복잡성** | 설정 간편, 관리 용이 | 복잡한 설정, 높은 확장성 |

## 모의투자 서비스 최적 사용법
- **RabbitMQ**: 주문 처리, 트랜잭션 워크플로우 (신뢰성 중요)
- **Kafka**: 시세 데이터 스트리밍, 사용자 행동 분석 (대용량 처리 중요)

핵심은 신뢰성이 필요한 트랜잭션에는 RabbitMQ, 대량 데이터나 분석용 이벤트에는 Kafka를 활용하는 하이브리드 접근법이 최적.


# VoiceBot 구현 계획

## 핵심 모듈 구성
1. **STT 모듈**
  - Whisper-tiny + INT8 양자화 (크기 ~90MB)
  - 스트리밍 처리 + VAD 통합
  - ONNX 변환 + TensorRT 가속

2. **LLM 처리**
  - LLaMA/Mistral 4-bit 양자화(7B→2GB)
  - 탐욕 디코딩 + 응답 토큰 제한(30-50)
  - 프롬프트 캐싱, 도메인 특화 QLoRA 파인튜닝
  - KV 캐시 최적화

3. **TTS 모듈**
  - Piper(70MB) + 음성 특성 캐싱
  - 문장 단위 병렬 처리
  - 모델 프루닝 및 양자화

## 병렬 처리 파이프라인

---
[음성 입력] → [STT 처리 시작] → 
  ↓
[부분 텍스트 결과] → [LLM 처리 시작] →
  ↓
[부분 응답 생성] → [TTS 처리 시작] → [부분 음성 출력] 

---
## 백엔드 통신 최적화
1. **프로토콜 선택**
   - 웹소켓/gRPC 활용 (HTTP/2 기반)
   - Binary 프로토콜: JSON 대신 FlatBuffers 사용
   - 멀티플렉싱으로 단일 연결에서 여러 스트림 처리

2. **네트워크 최적화**
   - 연결 풀링: 세션 간 연결 재사용
   - 적응형 압축: 네트워크 상태에 따른 압축 수준 조정
   - 증분 업데이트: 변경된 부분만 전송

3. **데이터 처리**
   - 스트리밍 전송: 청크 단위 점진적 처리
   - 양방향 스트림: 클라이언트-서버 간 지속적 데이터 흐름
   - 압축 오디오 코덱: Opus 활용 (낮은 비트레이트, 고품질)

## 성능 최적화 전략
1. **추론 가속**
   - TensorRT/ONNX Runtime으로 모든 모델 최적화
   - 혼합 정밀도 연산: FP16/BF16 활용
   - CUDA 그래프: 반복적 연산 패턴 최적화

2. **캐싱 메커니즘**
   - 응답 캐싱: 고빈도 쿼리는 사전 계산
   - 모델 중간 결과 캐싱: 부분 결과 재활용
   - 분산 캐시: Redis/Memcached로 서버 간 캐시 공유

3. **시스템 자원 관리**
   - CPU/GPU 균형: 전처리는 CPU, 모델 추론은 GPU
   - 메모리 풀링: 버퍼 재할당 방지
   - Zero-copy 설계: 불필요한 데이터 복사 제거

## 오류 처리 및 복원력
1. **장애 대응**
   - 대체 경로: 주 경로 실패 시 백업 서버로 자동 전환
   - 회로 차단기: 반복 실패 시 대체 처리 경로 활성화
   - 타임아웃 관리: 응답 지연 시 적절한 대응

2. **사용자 경험 유지**
   - 점진적 성능 저하: 과부하 시 품질은 낮추되 응답성 유지
   - 빈 음성 패딩: 처리 중임을 알리는 자연스러운 간투사
   - 폴백 응답: 서버 지연 시 일반적인 응답 제공

## 모니터링 및 최적화
1. **성능 측정**
   - 실시간 지연시간 추적: 각 모듈별 처리 시간 모니터링
   - 병목 감지: 자동 알림 및 대응
   - 사용자 경험 지표: 응답성, 정확도 종합 평가

2. **지속적 개선**
   - A/B 테스트 인프라: 최적화 전략 실시간 검증
   - 자동 튜닝: 시스템 부하에 따른 파라미터 조정
   - 피드백 루프: 사용자 반응 기반 모델 개선 


